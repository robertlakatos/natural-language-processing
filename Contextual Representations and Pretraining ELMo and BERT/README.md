# Modeling contexts of use: Contextual Representations and Pretraining. ELMo and BERT. 

## Materials

* [Lecture](https://github.com/robertlakatos/natural-language-processing/blob/master/Contextual%20Representations%20and%20Pretraining%20ELMo%20and%20BERT/cs224n-2020-lecture14-contextual-representations.pdf)
* [Video](https://www.youtube.com/watch?v=5vcj8kSwBCY&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=14)

## Assignments

## Suggested Readings

* [Contextual Word Representations: A Contextual Introduction. ](https://github.com/robertlakatos/natural-language-processing/blob/master/Contextual%20Representations%20and%20Pretraining%20ELMo%20and%20BERT/1902.06006.pdf)
* [The Illustrated BERT, ELMo, and co.](http://jalammar.github.io/illustrated-bert/)

# [BACK TO THE TABLE OF CONTENTS](https://github.com/robertlakatos/natural-language-processing/blob/master/README.md)