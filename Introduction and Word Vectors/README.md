# Natural Language Processing based on course of CS 224 of Stanford University

## Introduction and Word Vectors

[Lecture] (https://github.com/robertlakatos/natural-language-processing/blob/master/Introduction%20and%20Word%20Vectors/cs224n-2020-lecture01-wordvecs1.pdf)
[Note] (https://github.com/robertlakatos/natural-language-processing/blob/master/Introduction%20and%20Word%20Vectors/cs224n-2019-notes01-wordvecs1.pdf)

## Exercise
[Gensim word vectors example] (http://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html)

## Suggested Readings

[Word2Vec Tutorial - The Skip-Gram Model] (http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
[Efficient Estimation of Word Representations in Vector Space (original word2vec paper)] (http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
[Distributed Representations of Words and Phrases and their Compositionality (negative sampling paper)] (https://arxiv.org/pdf/1301.3781.pdf)