# Word Window Classification, Neural Networks

## Materials

* [Lecture]()
* [Note]()
* [Video](https://www.youtube.com/watch?v=XXtpJxZBa2c&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=9&t=0s)

## Suggested Readings

* [Statistical Machine Translation slides, CS224n 2015 (lectures 2/3/4)](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/syllabus.shtml)
* [Statistical Machine Translation (book by Philipp Koehn)](https://www.cambridge.org/core/books/statistical-machine-translation/94EADF9F680558E13BE759997553CDE5)
* [BLEU (original paper)]()
* [Sequence to Sequence Learning with Neural Networks (original seq2seq NMT paper)]()
* [Sequence Transduction with Recurrent Neural Networks (early seq2seq speech recognition paper)]()
* [Neural Machine Translation by Jointly Learning to Align and Translate (original seq2seq+attention paper)]()
* [Attention and Augmented Recurrent Neural Networks (blog post overview)](https://distill.pub/2016/augmented-rnns/)
* [Massive Exploration of Neural Machine Translation Architectures (practical advice for hyperparameter choices)]()

# [BACK TO THE TABLE OF CONTENTS](https://github.com/robertlakatos/natural-language-processing/blob/master/README.md)