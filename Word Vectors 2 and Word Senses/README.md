# Word Vectors 2 and Word Senses

## Materials

* [Lecture](https://github.com/robertlakatos/natural-language-processing/blob/master/Introduction%20and%20Word%20Vectors/cs224n-2020-lecture01-wordvecs1.pdf)
* [Note](https://github.com/robertlakatos/natural-language-processing/blob/master/Introduction%20and%20Word%20Vectors/cs224n-2019-notes01-wordvecs1.pdf)
* [Video](https://www.youtube.com/watch?v=kEMJRjEdNzM&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=3&t=0s)

## Suggested Readings

* [GloVe: Global Vectors for Word Representation (original GloVe paper)](https://nlp.stanford.edu/pubs/glove.pdf)
* [Improving Distributional Similarity with Lessons Learned from Word Embeddings](https://www.aclweb.org/anthology/Q15-1016.pdf)
* [Evaluation methods for unsupervised word embeddings](https://www.aclweb.org/anthology/D15-1036.pdf)
* [Evaluation methods for unsupervised word embeddings - Video](https://vimeo.com/156340833)

## Additional Readings
* [A Latent Variable Model Approach to PMI-based Word Embeddings](https://www.aclweb.org/anthology/Q16-1028.pdf)
* [Linear Algebraic Structure of Word Senses, with Applications to Polysemy](https://transacl.org/ojs/index.php/tacl/article/viewFile/1346/320)
* [On the Dimensionality of Word Embedding.](https://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding.pdf)